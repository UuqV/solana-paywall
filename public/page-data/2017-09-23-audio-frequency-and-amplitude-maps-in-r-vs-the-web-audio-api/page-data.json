{"componentChunkName":"component---src-templates-blog-post-js","path":"/2017-09-23-audio-frequency-and-amplitude-maps-in-r-vs-the-web-audio-api/","result":{"data":{"site":{"siteMetadata":{"title":"Kathryn Lovell","author":"Kathryn Lovell"}},"markdownRemark":{"id":"c9623e24-b887-5c4c-930b-2ab76d818027","excerpt":"In audio processing, not to mention creation, the humble amplitude map is an indespensible tool. When you load any sound file into Ableton, the first thing…","html":"<p>In audio processing, not to mention creation, the humble amplitude map is an indespensible tool. When you load any sound file into Ableton, the first thing Ableton does is put your track on a channel with a nice waveform view.</p>\n<p>For example, I will use the tune <a href=\"https://open.spotify.com/album/6tAGUJE3PCcsAUWe7y22hy\">I Am The Joker</a> by Boris Brejcha. Ableton makes your audio a grabbable object, and if you click on it, you’ll get a graph of amplitude over time down in the status bar.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/b27c59de159f5a3ef75a728dc1a2f463/4cc1c/statusbar.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 43.558282208588956%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIDBP/EABYBAQEBAAAAAAAAAAAAAAAAAAMAAf/aAAwDAQACEAMQAAABVKYFPSRLf//EABoQAAMAAwEAAAAAAAAAAAAAAAABAhMhMkL/2gAIAQEAAQUCbZlKrbPV9f/EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABgQAAMBAQAAAAAAAAAAAAAAAAABISAx/9oACAEBAAY/AqdRXj//xAAaEAEBAAIDAAAAAAAAAAAAAAABABAxIVGx/9oACAEBAAE/IekgagXgCYnq23//2gAMAwEAAgADAAAAEEQP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFhEBAQEAAAAAAAAAAAAAAAAAAAEx/9oACAECAQE/ELGP/8QAHhAAAgEEAwEAAAAAAAAAAAAAAAERITFB0VFxofD/2gAIAQEAAT8QcV1TliLS8MV0RVMRFdGHZa+3Paf/2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"StatusBar\"\n        title=\"StatusBar\"\n        src=\"/static/b27c59de159f5a3ef75a728dc1a2f463/6aca1/statusbar.jpg\"\n        srcset=\"/static/b27c59de159f5a3ef75a728dc1a2f463/d2f63/statusbar.jpg 163w,\n/static/b27c59de159f5a3ef75a728dc1a2f463/c989d/statusbar.jpg 325w,\n/static/b27c59de159f5a3ef75a728dc1a2f463/6aca1/statusbar.jpg 650w,\n/static/b27c59de159f5a3ef75a728dc1a2f463/7c09c/statusbar.jpg 975w,\n/static/b27c59de159f5a3ef75a728dc1a2f463/4cc1c/statusbar.jpg 1069w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>I’m going to zoom in to the middle of the song, where most of the action is here. Now we can start to see evidence of individual instruments in our techno track.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/b52bf3768001cf21154e6b0e8acafcdc/dd104/zoom.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 22.085889570552148%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAIAAAABPYjBAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA+UlEQVQI1wXB606CYAAAUN6tP7bRMhMQxIr7RT8KRMPlEPwwdeKMdIIDtabdrElKD9g5CD7elkbvhPPGjmdyMOWGXyLMVO8ouKniZTI8yPCoepnopFL3ILqp2vuTur+Kd2TsFJHsTx0ulFbI6Ilirdj68oz3L7jBCdHGZD/PDvhmQoHnXNlBr+E52+fM+LTi4vIIByFSbmwFe6c97mvuRn0IS2BO383FRoRWOoIZXmlBs7cD7Zc8A0nVp0Fg9X8wccgb0xszQYr3e7L1TRpr0ljS9egSxIXqgtBiVHgq1qJCNaT0FXEbo9wE19eEuWE7KWV9YMZrjpv9A9uRcqKYLFPeAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Zoom.png\"\n        title=\"Zoom.png\"\n        src=\"/static/b52bf3768001cf21154e6b0e8acafcdc/a6d36/zoom.png\"\n        srcset=\"/static/b52bf3768001cf21154e6b0e8acafcdc/222b7/zoom.png 163w,\n/static/b52bf3768001cf21154e6b0e8acafcdc/ff46a/zoom.png 325w,\n/static/b52bf3768001cf21154e6b0e8acafcdc/a6d36/zoom.png 650w,\n/static/b52bf3768001cf21154e6b0e8acafcdc/e548f/zoom.png 975w,\n/static/b52bf3768001cf21154e6b0e8acafcdc/dd104/zoom.png 1064w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>At first glance we can see the evidence of a banging techno kick drum, characterized by transients in this graph of amplitude over time, or how much energy our sound wave has at a given moment.</p>\n<p>An amplitude visualization such as this is fairly simple. When trying this myself, I first wanted to quickly script it in R. Luckily, the “tuneR” library allowed me to create a workable R object containing the data from a .wav file. I’ll feed it a piece of the song I used earlier.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">library(tuneR)\nsndObj &lt;- readWave('Data/1IAmTheJoker.wav')</code></pre></div>\n<p>In your R interpreter, you can view your audio wave object like so:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">> str(sndObj)\nFormal class 'Wave' [package \"tuneR\"] with 6 slots\n..@ left : int [1:88200] 0 -23 -49 -75 -104 -135 -164 -198 -234 -260 ...\n..@ right : int [1:88200] -1 -19 -42 -68 -94 -121 -153 -189 -215 -244 ...\n..@ stereo : logi TRUE\n..@ samp.rate: int 44100\n..@ bit : int 16\n..@ pcm : logi TRUE</code></pre></div>\n<p>The wave object consists of 6 “slots.” For now we will look at three of them: the two channels (@left and @right), and the sample rate (@samp.rate). The left and right channels contain 88200 sample points each. The sample rate tells us that there are 44100 audio samples to every 1 ms of the song. Thus, since our song snippet is 88200 samples, it contains 2 ms worth of data. This will be useful, as this is the “over time” part of “amplitude over time.” We’ll store this value as “timeArray.”</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">timeArray &lt;- (1:(88200)) / sndObj@samp.rate</code></pre></div>\n<p>Now, what’s actually in these 88200 samples? Well, first we’ll take each one in the left channel that corresponds to our x-axis.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">s1 &lt;- sndObj@left[1:(88200)] / sndObj@samp.rate</code></pre></div>\n<p>Our R function returns integer-typed samples. What’s the corresponding amplitude? We’ll need one more value to figure that out. Namely, we’ll need the bit depth of our wave file, @bit. Put simply what the bit depth tells us is that our sound sample values are mapped to integers that can range from -2^15 to (2^15)-1. Therefore, to map back to a continuous signal using a floating point value:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">s1 &lt;- s1 / 2^(sndObj@bit - 1)</code></pre></div>\n<p>Finally, to plot the amplitude graph:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">plot(timeArray, s1, type='l', col='black', xlab='Time (s)', ylab='Amplitude')</code></pre></div>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/7995a36a281d9c74ff2987aa63abfee4/9ecec/rplot.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAEDBQT/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHZjjqNdWLYCQf/xAAcEAACAgIDAAAAAAAAAAAAAAACAwABERMEEBL/2gAIAQEAAQUCJlCWypV5j0bGFxcksfAd/wD/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAcEAABBAMBAAAAAAAAAAAAAAAAARExQRAgMmH/2gAIAQEABj8CZVomsTR16Np//8QAHRAAAwACAgMAAAAAAAAAAAAAAAERIUEQMVGBwf/aAAgBAQABPyGEi7ZGu47eyCp0fakvhlB1oTrpDzx//9oADAMBAAIAAwAAABAwBzz/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/EB//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/EB//xAAcEAEAAwACAwAAAAAAAAAAAAABABEhMUFRwfD/2gAIAQEAAT8QQpRdG2B7j4RQaexYQBEPJMOs0jvwxc1rl0Q4h2OqtvOtyl3UAW0Cp//Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Rplot\"\n        title=\"Rplot\"\n        src=\"/static/7995a36a281d9c74ff2987aa63abfee4/6aca1/rplot.jpg\"\n        srcset=\"/static/7995a36a281d9c74ff2987aa63abfee4/d2f63/rplot.jpg 163w,\n/static/7995a36a281d9c74ff2987aa63abfee4/c989d/rplot.jpg 325w,\n/static/7995a36a281d9c74ff2987aa63abfee4/6aca1/rplot.jpg 650w,\n/static/7995a36a281d9c74ff2987aa63abfee4/7c09c/rplot.jpg 975w,\n/static/7995a36a281d9c74ff2987aa63abfee4/9ecec/rplot.jpg 1050w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>That sure was a lot of math though, wasn’t it? Well, with Web Audio you can create apps that have an analyzer without crunching the data yourself. <a href=\"https://jsfiddle.net/8mptzws0/50/\">Here’s a simple analyzer fiddle</a> I created that allows you to upload a file and view its (animated) waveform.</p>\n<p>This is an intriguing way to compare the design decisions of programming languages that are intended for entirely different purposes. With R, the script ends up overall much shorter and faster to write, but R is best for documents like the plot above. In Javascript, I had to write much more code simply to make my data useable and viewable, but this is unsurprising. Since Javascript is developed to create web applications, the authors chose to abstract away the math that I did in R, and instead expose interface design for modification. R instead offers me intimacy with the mathematics, but abstracts away the data parsing and visualization. This can be nice when exploring the data, but this would make trying to develop a powerful WebApp insufferable.</p>","frontmatter":{"title":"Audio Amplitude Vizualization in R and Web Applications","date":"September 23, 2017","description":null}}},"pageContext":{"slug":"/2017-09-23-audio-frequency-and-amplitude-maps-in-r-vs-the-web-audio-api/","previous":{"fields":{"slug":"/2017-09-21-the-jamboxx-a-jazz-enabled-midi-controller/"},"frontmatter":{"title":"The Jamboxx: A Jazz-Enabled MIDI Controller"}},"next":{"fields":{"slug":"/2017-10-13-the-fft/"},"frontmatter":{"title":"The Fast Fourier Transform: Composite Audio Visualizer with R and Web Audio"}}}},"staticQueryHashes":["63159454"]}